{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入库\n",
    "\n",
    "- **Pandas** => data manipulation\n",
    "- **NumPy** => numerical computations\n",
    "- **Matplotlib** and Seaborn => data visualization\n",
    "- **scikit-learn** => machine learning tasks\n",
    "- **os** => interacting with the operating system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as mtick\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据交互\n",
    "\n",
    "从指定的目录中读取 CSV 文件，将它们附加到 DataFrame(DataFrame) 列表中，连接到单个 DataFrame(df) ，并将其保存为 `datet.CSV`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = []\n",
    "files = os.listdir('D:\\\\')\n",
    "for file in files:\n",
    "    if file.endswith('.csv') and file.startswith('DATA_'):\n",
    "        filepath = os.path.join('D:\\\\', file)\n",
    "        df = pd.read_csv(filepath)\n",
    "        dataframes.append(df)\n",
    "\n",
    "df = pd.concat(dataframes, ignore_index=True)\n",
    "df.to_csv('dataset.csv', encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据清理\n",
    "\n",
    "Drop 掉时间戳的列："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('timestamp', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据检查\n",
    "\n",
    "提供有关 DataFrame 的形状、数据类型、汇总统计信息、缺失值(Null?)和目标变量的值计数的信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "print(df.info())\n",
    "print(df.describe(include='all'))\n",
    "\n",
    "if df.isnull().any() == True:\n",
    "    print(df.isnull().sum())\n",
    "    print('There are missing values in the data')\n",
    "\n",
    "ValueCounts_target = df['target'].value_counts()\n",
    "print(ValueCounts_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据可视化\n",
    "\n",
    "首先计算特征与目标变量之间的相关性，然后绘制相关性热力图来展示特征之间的相关性。Heatmap（热力图）使用颜色编码来表示不同特征之间的相关性程度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(df[df.columns[:]].corr()['target'][:].sort_values(ascending=False))      \n",
    "corr = df.corr()\n",
    "\n",
    "plt.figure(figsize=(17, 8))\n",
    "sns.heatmap(corr, \n",
    "            xticklabels=corr.columns,\n",
    "            linewidth=0.5,\n",
    "            yticklabels=corr.columns,\n",
    "            cmap=\"YlGnBu\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据建模\n",
    "\n",
    "将数据按照某种特定的规则进行分层处理，然后将每个分层（由特征向量组成）作为单独的数据集。最后，从原始的 DataFrame 中提取出特征矩阵 X 和目标向量 y，用于训练和测试模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['target']\n",
    "X_np = df.values\n",
    "layers = []\n",
    "current_layer = []\n",
    "\n",
    "for row in X_np:\n",
    "    if row[-1] != 0x00:\n",
    "        if current_layer:\n",
    "            layers.append(np.array(current_layer))\n",
    "        current_layer = [row]\n",
    "    else:\n",
    "        current_layer.append(row)\n",
    "\n",
    "if current_layer:\n",
    "    layers.append(np.array(current_layer))\n",
    "\n",
    "X = np.array(layers)\n",
    "X = X.drop('target', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 再次验证\n",
    "\n",
    "验证数据处理的正确性，打印出第一个和第二个分层的特征矩阵的形状，以确保它们符合预期。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X[0].shape, X[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据分割\n",
    "\n",
    "将数据分割成训练集和测试集，并对特征数据进行标准化处理，以确保在模型训练过程中每个特征的重要性相同。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.fit_transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练模型\n",
    "\n",
    "真正开始调用 PyTorch 的随机森林分类器模型，使用了 1000 棵决策树，并将训练好的模型保存在 `Rf_classifier` 中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rf_classifier = RandomForestClassifier(n_estimators=1000)\n",
    "Rf_classifier.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 评估模型\n",
    "\n",
    "计算并输出随机森林分类器在测试集上的准确率和混淆矩阵。准确率用于评估模型的整体性能，而混淆矩阵则提供了模型在不同类别下的分类情况。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf = Rf_classifier.predict(X_test_scaled)\n",
    "accu_rf = accuracy_score(y_pred_rf, y_test)\n",
    "print('Test Accuracy Random Forest Classifier:', accu_rf)\n",
    "print('Confusion Matrix Random Forest Classifier:\\n', confusion_matrix(y_pred_rf, y_test))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
